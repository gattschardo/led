% -*- mode: Noweb; noweb-code-mode: erlang-mode -*-

\documentclass{scrartcl}
\usepackage{noweb}

\title{led - Literate [[ed]]}
\author{Richard ``[[gattschardo]]'' Molitor}
\date{June 19, 2011 - \today} % this will eventually make sense

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}

Welcome to [[led]]! First, let's make clear what [[led]] is - it stands for
``literate [[ed]]'', where [[ed]] of course is the name of the standard text
editor (on \textsc{Unix} anyways). So [[led]] is just a clone of the original
[[ed]] -- whether it ever becomes fully functional only the future will show.

However it's not the primary goal of [[led]] to become a fully operational
[[ed]] clone, -- use the \textsc{Gnu} or some \textsc{Bsd} variant for that. So,
what is the purpose of this thing? This is where the ``literate'' part comes in:
It's just an experiement with literate programming -- I want to see whether this
approach to programming works out for me or not. Also, [[led]] is meant to teach
me some more things about [[ed]] itself (which is a quite nice
program)\footnote{To be true to my own word, I should actually be writing this
in [[ed]], but well, shame on me, looks like I'll be using \textsc{Vim},
mainly for its nice [[make]] integration\footnote{Looks like I'm using
\textsc{Emacs}, now}\footnote{Actually, I just wanted to nest
  footnotes}}, and also about programming in
Erlang, since that is the language in which it is implemented. Especially, one
of the goals is to figure out \textsc{Yecc}, the Erlang version of the well known
[[yacc]] parser generator.

%\newpage

\section{The Big Picture}

Since [[ed]] is a fairly simple program (which is of course among the reasons
I choose it for this experiement), it is split into five parts, each of which
is then described in it's own section:

\begin{description}

\item         [the scanner]
tokenizes the input for the parser.

\item        [the parser]
will parse lines of input into an abstract syntax representation (generated
from \textsc{Yecc} grammar).

\item        [the buffer]
is the abstract data structure modeling the edit buffer, supporting operations
such as [[get]], [[append]] and [[change]].
<<buffer head>>=
-module(ed_buffer).

-compile(export_all). % debug only
@

\item         [main]
will do the rest, that is, reading and writing buffers to file, initializing
the parser and buffer, shutting everything down
<<main head>>=
-module(ed_main).

-compile(export_all).% as above
@

\item        [the startup script]
will start the Erlang \textsc{VM} and pass in the command line arguments
(like, the file name) to main.
<<script head>>=
#!/bin/sh
@

\end{description}

\section{The Scanner}

The scanner must tokenize the input coming from an input port into an array
containing tuples of the form [[{Category, Line, Symbol}]] or, in case of
one-element categories [[{Symbol, Line}]].

At first I believed that I could get away with using the [[scan_erl_form]]
from the [[io]] module and post-processing it's output a bit, but this is not
going to work well, because I cannot have whitespace filtered out in regular
expressions, for example.

So, now there is my own\footnote{Brian Kernighan says, that he always writes
his scanners himself, too, so I guess I'm not in bad company} -- it always
only reads from \textit{stdin}, which should be appropriate for [[ed]]:

<<scan>>=
scan() ->
    case io:get_line( "led> " ) of
        eof ->
            { eof, 1 };
        { error, Reason } ->
            { error, Reason, 1 };
        Line ->
            { ok, lex( Line ), 1 }
    end.
@

The [[scan/0]] function tries to read a line, and calls [[lex/1]] on it if it
can get one. Our prompt for now is [[led>]], which is of course incorrect --
I'll use an empty prompt once I'm convinced that my clone is accurate enough.
The 1 which is always the last member of our tuple stands for the line number,
but since I don't care about multiple lines for now, it's just constant. I'm
not sure whether I will use it later or remove it entirely.

<<lex>>=
lex( Tokens ) ->
    lex( Tokens, []).

lex( [], Result ) ->
    lists:reverse( Result );
lex( [ Token | Ts ]= In, Result ) ->
    Digit   = is_digit( Token ),
    Special = is_special( Token ),
    Action  = is_action( Token ),
    White   = is_whitespace( Token ),
    if
        <<token type switch>>
    end.
@

This scanner is fairly simple-minded -- it never processes more than one
digit, unless it finds an integer. Since we cannot have arbitrary functions in
an Erlang if-statement, my solution for now is to call all these ''guards''
beforehand and just switch on their boolean results afterwards.

There are four conditions we are interested in:

\begin{description}

\item [digits:]
when we find a digit, we can simply let [[string:to_integer/1]] do the
conversion work, since it conveniently spits out the rest of the string after
the end of our integer:
<<token type switch>>=
Digit ->
    { Int, Rest } = string:to_integer( In ),
    lex( Rest, [{ integer, 1, Int }| Result ]);
@

\item [specials:]
these are some punctuation marks that ed treats specially in commands, like
the dot ``.'' or ``\$''. We convert them to atoms, to get rid of numeric
\textsc{Ascii} values:
<<token type switch>>=
Special ->  
    lex( Ts, [{ list_to_atom([ Token ]), 1 }| Result ]);
@

\item [actions:]
those are the letters that can be ed commands, like ``w'', ``q'', ``p''. We
get an atom that describes them a bit better, like:
<<token for p>>=
get_token( 112 ) -> % ascii 'p'
    print_tok;
@

and add that as a token:
<<token type switch>>=
Action ->
    lex( Ts, [{ get_token( Token ), 1, Token }| Result ]);
@

\item [whitespace]
is just \textit{space} and \textit{tab} here, because \textit{newline} is
already special, we just mark them:
<<token type switch>>=
White ->
    lex( Ts, [{ whitespace, 1, Token }| Result ]);
@

\end{description}

Everything else goes in the catch-all category ``letter'' as is:
<<token type switch>>=
true ->
    lex( Ts, [{ letter, 1, Token }| Result ])
@

Now all that remains to be done, is to define the classification functions
like [[is_digit/1]] and the [[get_token/1]] which gives the tokens for our
commands.

For digits it suffices to check the \textsc{Ascii} codes for 0 and 9 for now
(Erlang has no representation for single characters, so I'm giving their
numeric values, 48 and 57).

<<lex>>=
is_digit(Char) ->
    if
        Char >= 48, Char =< 57 ->
            true;
        Char < 48; Char > 57 ->
            false
    end.
@ 

[[is_special/1]], [[is_whitespace/1]] and [[is_action/1]] simply check for
\textsc{Ascii} codes:

<<classifiers>>=
is_special( 44 ) -> % ,
    true;
is_special( 10 ) -> % \n
    true;
is_special( 46 ) -> % .
    true;
is_special( 36 ) -> % $
    true;
is_special( 45 ) -> % -
    true;
is_special( 43 ) -> % +
    true;
is_special( _ ) ->
    false.

is_whitespace( 9 ) -> % \t
    true;
is_whitespace( 32) -> % space
    true;
is_whitespace( _ ) -> 
    false.

is_action( 97 ) -> % a
    true;
is_action( 99 ) -> % c
    true;
is_action( 100 ) -> % d
    true;
is_action( 101 ) -> % e
    true;
is_action( 103 ) -> % g
    true;
is_action( 105 ) -> % i
    true;
is_action( 106 ) -> % j
    true;
is_action( 112 ) -> % p
    true;
is_action( 113 ) -> % q
    true;
is_action( 114 ) -> % r
    true;
is_action( 115 ) -> % s
    true;
is_action( 117 ) -> % u
    true;
is_action( 119 ) -> % w
    true;
is_action( 120 ) -> % x
    true;
is_action( 121 ) -> % y
    true;
is_action( _ ) ->
    false.
@

And finally [[get_token/1]]:
<<tokens>>=
get_token( 97 ) -> % a
    append_tok;
get_token( 99 ) -> % c
    change_tok;
get_token( 100 ) -> % d
    delete_tok;
get_token( 101 ) -> % e
    edit_tok;
get_token( 103 ) -> % g
    global_tok;
get_token( 105 ) -> % i
    insert_tok;
get_token( 106 ) -> % j
    join_tok;
<<token for p>>
get_token( 113 ) -> % q
    quit_tok;
get_token( 114 ) -> % r
    read_tok;
get_token( 115 ) -> % s
    replace_tok;
get_token( 117 ) -> % u
    undo_tok;
get_token( 119 ) -> % w
    write_tok;
get_token( 120 ) -> % x
    paste_tok;
get_token( 121 ) -> % y
    yank_tok.
@ 

That's it, now lets bring it together in one file:

<<[[ed_scanner.erl]]>>=
-module(ed_scanner).

-compile(export_all).

<<scan>>
<<lex>>
<<classifiers>>
<<tokens>>
@

\section{The Parser}

Ok, so let's start defining the grammar for the parser. Of course, in practice
it may not be very rewarding to write a grammar for [[ed]] input, since it's
not very complex and a hand-coded parser should work fine. But remember, I'm
trying to learn \textsc{Yecc}, here\footnote{Also note that Pippijn says a formal
grammar is always a good thing to have, since it will always be easier to
maintain than a hand-written parser}.

The terminal symbols for the grammar are as follows:

<<parser terminals>>=
Terminals 
% specials:
',' '\n' '.' '$' '-' '+'
% categories:
'integer' 'letter'
% tokens
'print_tok' 'quit_tok'.
@

Note that [[integer]] and [[atom]] are provided by [[erl_scan]] and are simply
Erlang integers resp. atoms.

The nonterminals that we will need are the following

<<parser nonterminals>>=
Nonterminals input command region print quit.
@

We will of course be parsing commands one by one, but in non-interactive mode
there can of course be several at once:

<<parser root>>=
Rootsymbol input.
@

Actually, this might not be what I need, though, the question is how the
parsing works, that is, whether is parses incomplete input. If not, I'll need
to restart a new parser for each command, and then of course, the root symbol
can just be [[command]] instead of [[commands]].

To get a general idea how \textsc{Yecc} input looks like, here is the print
action:

<<parser print>>=
print ->
    region 'print_tok' :
        {print, '$1'}.
print ->
    'print_tok' :
        {print, [region, {'.', 1}]}.
@

<<parser top>>=
input ->
    command '\n' :
        '$1'.

command ->
    print :
        '$1'.
command ->
    quit :
        '$1'.

quit ->
    'quit_tok' :
        {quit, []}.

region ->
    'integer' ',' 'integer' :
        [region, '$1', '$2', '$3'].
region ->
    'integer' :
        [region, '$1'].
region ->
    '.' :
        [region, '$1'] .
region ->
    '$' :
        [region, '$1'] .
region ->
    '-' 'integer' :
        [region, '$1', '$2'].
region ->
    '+' 'integer' :
        [region, '$1', '$2'].
region ->
    '-' :
        [region, '$1', {integer, 1, 1}].
region ->
    '+' :
        [region, '$1', {integer, 1, 1}].
@

So, all in all, the parser becomes:
<<[[ed_parser.yrl]]>>=
<<parser nonterminals>>
<<parser terminals>>
<<parser root>>
<<parser top>>
<<parser print>>
@

\section{The Buffer Data Structure}

<<[[ed_buffer.erl]]>>=
<<buffer head>>
@

\section{The Main Module}

For now, the main module just parses lines of input and either prints
the resulting syntax tree, or exits.

<<main parse>>=
start() ->
    loop().

loop() ->
    case step() of
        true ->
            loop();
        false ->
            "Bye"
    end.

step() ->
    { ok, T, 1 }= ed_scanner:scan(),
    case ed_parser:parse( T ) of
        { ok, S } ->
            if
                is_tuple( S ), S == { quit, [] } ->
                    false;
                true ->
                    io:format( "S-Tree: ~w~n", [ S ]),
                    true
            end;
        { error, { _Line, ed_parser, [ Err, Message ]}} ->
            io:format( "? ~s~s~n", [ Err, Message ]),
            true
    end.
@ 

<<[[ed_main.erl]]>>=
<<main head>>
<<main parse>>
@

\section{The Startup Script}

Just start the main method (without passing any arguments, for now).

<<[[led.sh]]>>=
<<script head>>

echo "Hello, led!"
erl -noshell -pa ~/code/led -s ed_main start -s init stop
@

\section{Conclusion}

It's fun, try it!

\section{Defined Chunks}

\nowebchunks

%\section{Index}
%
%\nowebindex

\end{document}

% vim: se tw=78 sw=4 et:
